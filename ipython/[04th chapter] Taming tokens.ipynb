{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boilerplate Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import time\n",
    "\n",
    "ELASTICSEARCH_URL = os.environ.get('ELASTICSEARCH_URL', 'http://localhost:9200')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2.2 Analysis for precision or recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    with open('tmdb.json') as f:\n",
    "         return json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex(settings):\n",
    "    response = requests.delete(ELASTICSEARCH_URL + '/my_library')\n",
    "    response = requests.put(ELASTICSEARCH_URL + '/my_library', json=settings)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, analyzer):\n",
    "    response = requests.get(\n",
    "        ELASTICSEARCH_URL + '/my_library/_analyze', \n",
    "        json={\n",
    "            'text': text,\n",
    "            'analyzer': analyzer\n",
    "        }\n",
    "    ).json()\n",
    "\n",
    "    print(''.join(['[{}]'.format(token_term['token']) for token_term in response['tokens']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reindex({\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"standard_clone\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [ \"standard\", \"lowercase\", \"stop\" ]\n",
    "}}}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dr][strangelove][how][i][learned][stop][worrying][love][bomb]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"Dr. Strangelove: Or How I Learned to Stop Worrying and Love the Bomb\", 'standard_clone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reindex({\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"english_stop\": {\n",
    "          \"type\":       \"stop\",\n",
    "          \"stopwords\":  \"_english_\"},\n",
    "        \"english_keywords\": {\n",
    "          \"type\":       \"keyword_marker\",\n",
    "          \"keywords\":   []},\n",
    "        \"english_stemmer\": {\n",
    "          \"type\":       \"stemmer\",\n",
    "          \"language\":   \"english\"},\n",
    "        \"english_possessive_stemmer\": {\n",
    "          \"type\":       \"stemmer\",\n",
    "          \"language\":   \"possessive_english\"}},\n",
    "      \"analyzer\": {\n",
    "        \"english_clone\": {\n",
    "          \"tokenizer\":  \"standard\",\n",
    "          \"filter\": [\n",
    "            \"english_possessive_stemmer\",\n",
    "            \"lowercase\",\n",
    "            \"english_stop\",\n",
    "            \"english_keywords\",\n",
    "            \"english_stemmer\"]\n",
    "}}}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dr][strangelov][how][i][learn][stop][worri][love][bomb]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"Dr. Strangelove: Or How I Learned to Stop Worrying and Love the Bomb\", 'english_clone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2.3 Taking recall to extremes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phonetic analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticsearch\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker exec elasticsearch bash -c \"bin/elasticsearch-plugin install analysis-phonetic > /dev/null\"\n",
    "docker restart elasticsearch\n",
    "sleep 30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reindex({\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"phonetic\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"standard\",\n",
    "            \"lowercase\",\n",
    "            \"my_doublemetaphone\"]}},\n",
    "      \"filter\": {\n",
    "        \"my_doublemetaphone\": {\n",
    "          \"type\": \"phonetic\",\n",
    "          \"encoder\": \"doublemetaphone\",\n",
    "           \"replace\": True\n",
    "}}}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MSJ][MSK][FRM][TL][LM]\n",
      "[MSJ][MSK][FRM][TL][LM]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"message from Dalai Lama\", 'phonetic')\n",
    "tokenize(\"message from tall llama\", 'phonetic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3.1 Scoring strength of a feature in a single field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/example/1', json={ \"title\":\"apple apple apple apple apple\" }))\n",
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/example/2', json={ \"title\":\"apple apple apple banana banana\" }))\n",
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/example/3', json={ \"title\":\"apple banana blueberry coconut\" }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for apple apple apple apple apple\n",
      "0.51040375, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.51040375, score(doc=0,freq=5.0 = termFreq=5.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.7741936, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      5.0, termFreq=5.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      5.0, avgFieldLength\n",
      "      5.0, fieldLength\n",
      "\n",
      "Explain for apple banana blueberry coconut\n",
      "0.2876821, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.2876821, score(doc=0,freq=1.0 = termFreq=1.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.0, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      1.0, termFreq=1.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      4.0, avgFieldLength\n",
      "      4.0, fieldLength\n",
      "\n",
      "Explain for apple apple apple banana banana\n",
      "0.26240674, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.26240674, score(doc=0,freq=3.0 = termFreq=3.0), product of:\n",
      "    0.18232156, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      2.0, docFreq\n",
      "      2.0, docCount\n",
      "    1.4392524, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      3.0, termFreq=3.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      3.5, avgFieldLength\n",
      "      5.0, fieldLength\n",
      "\n",
      "Explain for apples apple\n",
      "0.22108285, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.22108285, score(doc=0,freq=1.0 = termFreq=1.0), product of:\n",
      "    0.18232156, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      2.0, docFreq\n",
      "      2.0, docCount\n",
      "    1.2125984, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      1.0, termFreq=1.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      3.5, avgFieldLength\n",
      "      2.0, fieldLength\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def simpler_explain(explain_json, depth=0):\n",
    "    result = \" \" * (depth * 2) + \"%s, %s\\n\" % (explain_json['value'], explain_json['description'].replace('\\n', ''))\n",
    "    if 'details' in explain_json:\n",
    "        for detail in explain_json['details']:\n",
    "            result += simpler_explain(detail, depth=depth+1)\n",
    "    return result\n",
    "\n",
    "query = {\n",
    "  \"explain\": \"true\",\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"title\": \"apple\"\n",
    "}}}\n",
    "response = requests.get(ELASTICSEARCH_URL + '/my_library/example/_search', json=query)\n",
    "data = response.json()\n",
    "for i in range(len(data['hits']['hits'])):\n",
    "    print(\"Explain for %s\" % data['hits']['hits'][i]['_source']['title'])\n",
    "    print(simpler_explain(data['hits']['hits'][i]['_explanation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/example/4', json={ \"title\":\"apples apple\" }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for apple apple apple apple apple\n",
      "0.51040375, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.51040375, score(doc=0,freq=5.0 = termFreq=5.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.7741936, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      5.0, termFreq=5.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      5.0, avgFieldLength\n",
      "      5.0, fieldLength\n",
      "\n",
      "Explain for apple banana blueberry coconut\n",
      "0.2876821, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.2876821, score(doc=0,freq=1.0 = termFreq=1.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.0, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      1.0, termFreq=1.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      4.0, avgFieldLength\n",
      "      4.0, fieldLength\n",
      "\n",
      "Explain for apple apple apple banana banana\n",
      "0.26240674, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.26240674, score(doc=0,freq=3.0 = termFreq=3.0), product of:\n",
      "    0.18232156, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      2.0, docFreq\n",
      "      2.0, docCount\n",
      "    1.4392524, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      3.0, termFreq=3.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      3.5, avgFieldLength\n",
      "      5.0, fieldLength\n",
      "\n",
      "Explain for apples apple\n",
      "0.22108285, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.22108285, score(doc=0,freq=1.0 = termFreq=1.0), product of:\n",
      "    0.18232156, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      2.0, docFreq\n",
      "      2.0, docCount\n",
      "    1.2125984, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      1.0, termFreq=1.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      3.5, avgFieldLength\n",
      "      2.0, fieldLength\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "  \"explain\": \"true\",\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"title\": \"apple\"\n",
    "}}}\n",
    "response = requests.get(ELASTICSEARCH_URL + '/my_library/example/_search', json=query)\n",
    "data = response.json()\n",
    "for i in range(len(data['hits']['hits'])):\n",
    "    print(\"Explain for %s\" % data['hits']['hits'][i]['_source']['title'])\n",
    "    print(simpler_explain(data['hits']['hits'][i]['_explanation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reindex({\n",
    "    'mappings': {\n",
    "       'example': {\n",
    "            'properties': {\n",
    "               'title': {\n",
    "                   'type': 'text',\n",
    "                   'analyzer': 'english'},\n",
    "            'overview': {\n",
    "                   'type': 'text',\n",
    "                   'analyzer': 'english'\n",
    "}}}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [201]>\n",
      "<Response [201]>\n",
      "<Response [201]>\n",
      "<Response [201]>\n"
     ]
    }
   ],
   "source": [
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/example/1', json={ \"title\":\"apple apple apple apple apple\" }))\n",
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/example/2', json={ \"title\":\"apple apple apple banana banana\" }))\n",
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/example/3', json={ \"title\":\"apple banana blueberry coconut\" }))\n",
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/example/4', json={ \"title\":\"apples apple\" }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for apple apple apple apple apple\n",
      "0.51040375, weight(title:appl in 0) [PerFieldSimilarity], result of:\n",
      "  0.51040375, score(doc=0,freq=5.0 = termFreq=5.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.7741936, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      5.0, termFreq=5.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      5.0, avgFieldLength\n",
      "      5.0, fieldLength\n",
      "\n",
      "Explain for apple banana blueberry coconut\n",
      "0.2876821, weight(title:appl in 0) [PerFieldSimilarity], result of:\n",
      "  0.2876821, score(doc=0,freq=1.0 = termFreq=1.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.0, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      1.0, termFreq=1.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      4.0, avgFieldLength\n",
      "      4.0, fieldLength\n",
      "\n",
      "Explain for apples apple\n",
      "0.28505096, weight(title:appl in 1) [PerFieldSimilarity], result of:\n",
      "  0.28505096, score(doc=1,freq=2.0 = termFreq=2.0), product of:\n",
      "    0.18232156, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      2.0, docFreq\n",
      "      2.0, docCount\n",
      "    1.5634518, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      2.0, termFreq=2.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      3.5, avgFieldLength\n",
      "      2.0, fieldLength\n",
      "\n",
      "Explain for apple apple apple banana banana\n",
      "0.26240674, weight(title:appl in 0) [PerFieldSimilarity], result of:\n",
      "  0.26240674, score(doc=0,freq=3.0 = termFreq=3.0), product of:\n",
      "    0.18232156, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      2.0, docFreq\n",
      "      2.0, docCount\n",
      "    1.4392524, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      3.0, termFreq=3.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      3.5, avgFieldLength\n",
      "      5.0, fieldLength\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "  \"explain\": \"true\",\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"title\": \"apple\"\n",
    "}}}\n",
    "response = requests.get(ELASTICSEARCH_URL + '/my_library/example/_search', json=query)\n",
    "data = response.json()\n",
    "for i in range(len(data['hits']['hits'])):\n",
    "    print(\"Explain for %s\" % data['hits']['hits'][i]['_source']['title'])\n",
    "    print(simpler_explain(data['hits']['hits'][i]['_explanation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "Takeaways:\n",
    "\n",
    "1. ?\n",
    "\n",
    "Experiments:\n",
    "\n",
    "- **[1]**: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
