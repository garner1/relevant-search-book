{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boilerplate Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import time\n",
    "\n",
    "ELASTICSEARCH_URL = os.environ.get('ELASTICSEARCH_URL', 'http://localhost:9200')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2.2 Analysis for precision or recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    with open('tmdb.json') as f:\n",
    "         return json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex(settings):\n",
    "    response = requests.delete(ELASTICSEARCH_URL + '/my_library')\n",
    "    response = requests.put(ELASTICSEARCH_URL + '/my_library', json=settings)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, analyzer):\n",
    "    response = requests.get(\n",
    "        ELASTICSEARCH_URL + '/my_library/_analyze', \n",
    "        json={\n",
    "            'text': text,\n",
    "            'analyzer': analyzer\n",
    "        }\n",
    "    ).json()\n",
    "\n",
    "    print(''.join(['[{}]'.format(token_term['token']) for token_term in response['tokens']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reindex({\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"standard_clone\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [ \"standard\", \"lowercase\", \"stop\" ]\n",
    "}}}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dr][strangelove][how][i][learned][stop][worrying][love][bomb]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"Dr. Strangelove: Or How I Learned to Stop Worrying and Love the Bomb\", 'standard_clone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reindex({\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"english_stop\": {\n",
    "          \"type\":       \"stop\",\n",
    "          \"stopwords\":  \"_english_\"},\n",
    "        \"english_keywords\": {\n",
    "          \"type\":       \"keyword_marker\",\n",
    "          \"keywords\":   []},\n",
    "        \"english_stemmer\": {\n",
    "          \"type\":       \"stemmer\",\n",
    "          \"language\":   \"english\"},\n",
    "        \"english_possessive_stemmer\": {\n",
    "          \"type\":       \"stemmer\",\n",
    "          \"language\":   \"possessive_english\"}},\n",
    "      \"analyzer\": {\n",
    "        \"english_clone\": {\n",
    "          \"tokenizer\":  \"standard\",\n",
    "          \"filter\": [\n",
    "            \"english_possessive_stemmer\",\n",
    "            \"lowercase\",\n",
    "            \"english_stop\",\n",
    "            \"english_keywords\",\n",
    "            \"english_stemmer\"]\n",
    "}}}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dr][strangelov][how][i][learn][stop][worri][love][bomb]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"Dr. Strangelove: Or How I Learned to Stop Worrying and Love the Bomb\", 'english_clone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2.3 Taking recall to extremes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phonetic analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticsearch\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker exec elasticsearch bash -c \"bin/elasticsearch-plugin install analysis-phonetic > /dev/null\"\n",
    "docker restart elasticsearch\n",
    "sleep 60s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reindex({\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"phonetic\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"standard\",\n",
    "            \"lowercase\",\n",
    "            \"my_doublemetaphone\"]}},\n",
    "      \"filter\": {\n",
    "        \"my_doublemetaphone\": {\n",
    "          \"type\": \"phonetic\",\n",
    "          \"encoder\": \"doublemetaphone\",\n",
    "           \"replace\": True\n",
    "}}}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MSJ][MSK][FRM][TL][LM]\n",
      "[MSJ][MSK][FRM][TL][LM]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"message from Dalai Lama\", 'phonetic')\n",
    "tokenize(\"message from tall llama\", 'phonetic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3.1 Scoring strength of a feature in a single field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [201]>\n",
      "<Response [201]>\n",
      "<Response [201]>\n"
     ]
    }
   ],
   "source": [
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/example/1', json={ \"title\":\"apple apple apple apple apple\" }))\n",
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/example/2', json={ \"title\":\"apple apple apple banana banana\" }))\n",
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/example/3', json={ \"title\":\"apple banana blueberry coconut\" }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for apple apple apple apple apple\n",
      "0.51040375, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.51040375, score(doc=0,freq=5.0 = termFreq=5.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.7741936, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      5.0, termFreq=5.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      5.0, avgFieldLength\n",
      "      5.0, fieldLength\n",
      "\n",
      "Explain for apple apple apple banana banana\n",
      "0.4520719, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.4520719, score(doc=0,freq=3.0 = termFreq=3.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.5714288, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      3.0, termFreq=3.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      5.0, avgFieldLength\n",
      "      5.0, fieldLength\n",
      "\n",
      "Explain for apple banana blueberry coconut\n",
      "0.2876821, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.2876821, score(doc=0,freq=1.0 = termFreq=1.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.0, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      1.0, termFreq=1.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      4.0, avgFieldLength\n",
      "      4.0, fieldLength\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def simpler_explain(explain_json, depth=0):\n",
    "    result = \" \" * (depth * 2) + \"%s, %s\\n\" % (explain_json['value'], explain_json['description'].replace('\\n', ''))\n",
    "    if 'details' in explain_json:\n",
    "        for detail in explain_json['details']:\n",
    "            result += simpler_explain(detail, depth=depth+1)\n",
    "    return result\n",
    "\n",
    "query = {\n",
    "  \"explain\": \"true\",\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"title\": \"apple\"\n",
    "}}}\n",
    "response = requests.get(ELASTICSEARCH_URL + '/my_library/example/_search', json=query)\n",
    "data = response.json()\n",
    "for i in range(len(data['hits']['hits'])):\n",
    "    print(\"Explain for %s\" % data['hits']['hits'][i]['_source']['title'])\n",
    "    print(simpler_explain(data['hits']['hits'][i]['_explanation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [201]>\n"
     ]
    }
   ],
   "source": [
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/example/4', json={ \"title\":\"apples apple\" }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for apple apple apple apple apple\n",
      "0.51040375, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.51040375, score(doc=0,freq=5.0 = termFreq=5.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.7741936, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      5.0, termFreq=5.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      5.0, avgFieldLength\n",
      "      5.0, fieldLength\n",
      "\n",
      "Explain for apple banana blueberry coconut\n",
      "0.2876821, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.2876821, score(doc=0,freq=1.0 = termFreq=1.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.0, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      1.0, termFreq=1.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      4.0, avgFieldLength\n",
      "      4.0, fieldLength\n",
      "\n",
      "Explain for apple apple apple banana banana\n",
      "0.26240674, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.26240674, score(doc=0,freq=3.0 = termFreq=3.0), product of:\n",
      "    0.18232156, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      2.0, docFreq\n",
      "      2.0, docCount\n",
      "    1.4392524, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      3.0, termFreq=3.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      3.5, avgFieldLength\n",
      "      5.0, fieldLength\n",
      "\n",
      "Explain for apples apple\n",
      "0.22108285, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.22108285, score(doc=0,freq=1.0 = termFreq=1.0), product of:\n",
      "    0.18232156, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      2.0, docFreq\n",
      "      2.0, docCount\n",
      "    1.2125984, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      1.0, termFreq=1.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      3.5, avgFieldLength\n",
      "      2.0, fieldLength\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "  \"explain\": \"true\",\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"title\": \"apple\"\n",
    "}}}\n",
    "response = requests.get(ELASTICSEARCH_URL + '/my_library/example/_search', json=query)\n",
    "data = response.json()\n",
    "for i in range(len(data['hits']['hits'])):\n",
    "    print(\"Explain for %s\" % data['hits']['hits'][i]['_source']['title'])\n",
    "    print(simpler_explain(data['hits']['hits'][i]['_explanation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reindex({\n",
    "    'mappings': {\n",
    "       'example': {\n",
    "            'properties': {\n",
    "               'title': {\n",
    "                   'type': 'text',\n",
    "                   'analyzer': 'english'},\n",
    "            'overview': {\n",
    "                   'type': 'text',\n",
    "                   'analyzer': 'english'\n",
    "}}}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [201]>\n",
      "<Response [201]>\n",
      "<Response [201]>\n",
      "<Response [201]>\n"
     ]
    }
   ],
   "source": [
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/example/1', json={ \"title\":\"apple apple apple apple apple\" }))\n",
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/example/2', json={ \"title\":\"apple apple apple banana banana\" }))\n",
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/example/3', json={ \"title\":\"apple banana blueberry coconut\" }))\n",
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/example/4', json={ \"title\":\"apples apple\" }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for apple apple apple apple apple\n",
      "0.51040375, weight(title:appl in 0) [PerFieldSimilarity], result of:\n",
      "  0.51040375, score(doc=0,freq=5.0 = termFreq=5.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.7741936, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      5.0, termFreq=5.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      5.0, avgFieldLength\n",
      "      5.0, fieldLength\n",
      "\n",
      "Explain for apple banana blueberry coconut\n",
      "0.2876821, weight(title:appl in 0) [PerFieldSimilarity], result of:\n",
      "  0.2876821, score(doc=0,freq=1.0 = termFreq=1.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.0, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      1.0, termFreq=1.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      4.0, avgFieldLength\n",
      "      4.0, fieldLength\n",
      "\n",
      "Explain for apples apple\n",
      "0.28505096, weight(title:appl in 1) [PerFieldSimilarity], result of:\n",
      "  0.28505096, score(doc=1,freq=2.0 = termFreq=2.0), product of:\n",
      "    0.18232156, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      2.0, docFreq\n",
      "      2.0, docCount\n",
      "    1.5634518, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      2.0, termFreq=2.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      3.5, avgFieldLength\n",
      "      2.0, fieldLength\n",
      "\n",
      "Explain for apple apple apple banana banana\n",
      "0.26240674, weight(title:appl in 0) [PerFieldSimilarity], result of:\n",
      "  0.26240674, score(doc=0,freq=3.0 = termFreq=3.0), product of:\n",
      "    0.18232156, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      2.0, docFreq\n",
      "      2.0, docCount\n",
      "    1.4392524, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      3.0, termFreq=3.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      3.5, avgFieldLength\n",
      "      5.0, fieldLength\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "  \"explain\": \"true\",\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"title\": \"apple\"\n",
    "}}}\n",
    "response = requests.get(ELASTICSEARCH_URL + '/my_library/example/_search', json=query)\n",
    "data = response.json()\n",
    "for i in range(len(data['hits']['hits'])):\n",
    "    print(\"Explain for %s\" % data['hits']['hits'][i]['_source']['title'])\n",
    "    print(simpler_explain(data['hits']['hits'][i]['_explanation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4.1 Dealing with delimiters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reindex({\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"acronyms\": {\n",
    "          \"type\": \"word_delimiter\",\n",
    "          \"catenate_all\": True,\n",
    "          \"generate_word_parts\": False,\n",
    "          \"generate_number_parts\": False}},\n",
    "      \"analyzer\": {\n",
    "        \"standard_with_acronyms\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\"standard\",\"lowercase\",\"acronyms\"]\n",
    "}}}}})\n",
    "tokenize(\"I.B.M. versus IBM versus ibm\", 'standard_with_acronyms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phone numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18008675309][8008675309][8675309]\n"
     ]
    }
   ],
   "source": [
    "reindex({\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"phone_num_filter\": {\n",
    "          \"type\": \"word_delimiter\",\n",
    "          \"catenate_all\": True,\n",
    "          \"generate_number_parts\": False},\n",
    "        \"phone_num_parts\": {\n",
    "          \"type\": \"pattern_capture\",\n",
    "          \"patterns\":[\"(\\\\d{7}$)\",\"(\\\\d{10}$)\"],\n",
    "          \"preserve_original\": True}},\n",
    "      \"analyzer\": {\n",
    "        \"phone_num\": {\n",
    "          \"tokenizer\": \"keyword\",\n",
    "         \"filter\": [\"phone_num_filter\",\"phone_num_parts\"]\n",
    "}}}}})\n",
    "tokenize(\"1(800)867-5309\", 'phone_num')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4.2. Capturing meaning with synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [201]>\n",
      "<Response [201]>\n",
      "<Response [201]>\n"
     ]
    }
   ],
   "source": [
    "reindex({\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"english_stop\": {\n",
    "          \"type\":       \"stop\",\n",
    "          \"stopwords\":  \"_english_\"},\n",
    "        \"english_keywords\": {\n",
    "          \"type\":       \"keyword_marker\",\n",
    "          \"keywords\":   []},\n",
    "        \"english_stemmer\": {\n",
    "          \"type\":       \"stemmer\",\n",
    "          \"language\":   \"english\"},\n",
    "        \"english_possessive_stemmer\": {\n",
    "          \"type\":       \"stemmer\",\n",
    "          \"language\":   \"possessive_english\"},\n",
    "        \"retail_syn_filter\": {\n",
    "          \"type\": \"synonym\",\n",
    "          \"synonyms\": [\n",
    "            \"dress shoe, dress shoes => dress_shoe, shoe\"\n",
    "          ]}},\n",
    "      \"analyzer\": {\n",
    "        \"retail_analyzer\": {\n",
    "          \"tokenizer\":  \"standard\",\n",
    "          \"filter\": [\n",
    "            \"english_possessive_stemmer\",\n",
    "            \"lowercase\",\n",
    "            \"retail_syn_filter\",\n",
    "            \"english_keywords\",\n",
    "            \"english_stemmer\"]}}}},\n",
    "  \"mappings\": {\n",
    "    \"items\": {\n",
    "      \"properties\": {\n",
    "        \"desc\": {\n",
    "          \"type\": \"text\",\n",
    "          \"analyzer\": \"retail_analyzer\",\n",
    "}}}}})\n",
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/items/1', json={ \"desc\": \"bob's brand dress shoes are the bomb diggity\" }))\n",
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/items/2', json={ \"desc\": \"this little black dress is sure to impress\" }))\n",
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/items/3', json={ \"desc\": \"tennis shoes... you know, for tennis\" }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for this little black dress is sure to impress\n",
      "0.2876821, weight(desc:dress in 0) [PerFieldSimilarity], result of:\n",
      "  0.2876821, score(doc=0,freq=1.0 = termFreq=1.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.0, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      1.0, termFreq=1.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      8.0, avgFieldLength\n",
      "      8.0, fieldLength\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "  \"explain\": \"true\",\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"desc\": \"dress\"\n",
    "}}}\n",
    "response = requests.get(ELASTICSEARCH_URL + '/my_library/items/_search', json=query)\n",
    "data = response.json()\n",
    "for i in range(len(data['hits']['hits'])):\n",
    "    print(\"Explain for %s\" % data['hits']['hits'][i]['_source']['desc'])\n",
    "    print(simpler_explain(data['hits']['hits'][i]['_explanation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for bob's brand dress shoes are the bomb diggity\n",
      "0.30318588, weight(desc:shoe in 0) [PerFieldSimilarity], result of:\n",
      "  0.30318588, score(doc=0,freq=1.0 = termFreq=1.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.0538921, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      1.0, termFreq=1.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      8.0, avgFieldLength\n",
      "      7.0, fieldLength\n",
      "\n",
      "Explain for tennis shoes... you know, for tennis\n",
      "0.2876821, weight(desc:shoe in 0) [PerFieldSimilarity], result of:\n",
      "  0.2876821, score(doc=0,freq=1.0 = termFreq=1.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.0, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      1.0, termFreq=1.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      6.0, avgFieldLength\n",
      "      6.0, fieldLength\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "  \"explain\": \"true\",\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"desc\": \"shoes\"\n",
    "}}}\n",
    "response = requests.get(ELASTICSEARCH_URL + '/my_library/items/_search', json=query)\n",
    "data = response.json()\n",
    "for i in range(len(data['hits']['hits'])):\n",
    "    print(\"Explain for %s\" % data['hits']['hits'][i]['_source']['desc'])\n",
    "    print(simpler_explain(data['hits']['hits'][i]['_explanation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for bob's brand dress shoes are the bomb diggity\n",
      "0.40997607, weight(Synonym(desc:dress_sho desc:shoe) in 0) [PerFieldSimilarity], result of:\n",
      "  0.40997607, score(doc=0,freq=2.0 = termFreq=2.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.4251012, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      2.0, termFreq=2.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      8.0, avgFieldLength\n",
      "      7.0, fieldLength\n",
      "\n",
      "Explain for tennis shoes... you know, for tennis\n",
      "0.2876821, weight(Synonym(desc:dress_sho desc:shoe) in 0) [PerFieldSimilarity], result of:\n",
      "  0.2876821, score(doc=0,freq=1.0 = termFreq=1.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.0, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      1.0, termFreq=1.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      6.0, avgFieldLength\n",
      "      6.0, fieldLength\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "  \"explain\": \"true\",\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"desc\": \"dress shoes\"\n",
    "}}}\n",
    "response = requests.get(ELASTICSEARCH_URL + '/my_library/items/_search', json=query)\n",
    "data = response.json()\n",
    "for i in range(len(data['hits']['hits'])):\n",
    "    print(\"Explain for %s\" % data['hits']['hits'][i]['_source']['desc'])\n",
    "    print(simpler_explain(data['hits']['hits'][i]['_explanation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [201]>\n",
      "<Response [201]>\n",
      "<Response [201]>\n"
     ]
    }
   ],
   "source": [
    "a = reindex({\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"english_stop\": {\n",
    "          \"type\":       \"stop\",\n",
    "          \"stopwords\":  \"_english_\"},\n",
    "        \"english_keywords\": {\n",
    "          \"type\":       \"keyword_marker\",\n",
    "          \"keywords\":   []},\n",
    "        \"english_stemmer\": {\n",
    "          \"type\":       \"stemmer\",\n",
    "          \"language\":   \"english\"},\n",
    "        \"english_possessive_stemmer\": {\n",
    "          \"type\":       \"stemmer\",\n",
    "          \"language\":   \"possessive_english\"},\n",
    "        \"retail_syn_filter_index\": {\n",
    "          \"type\": \"synonym\",\n",
    "          \"synonyms\": [\n",
    "            \"dress shoe, dress shoes => dress_shoe, shoe\"\n",
    "          ]},\n",
    "        \"retail_syn_filter_search\": {\n",
    "          \"type\": \"synonym\",\n",
    "          \"synonyms\": [\n",
    "            \"dress shoe, dress shoes => dress_shoe\"\n",
    "          ]}},\n",
    "      \"analyzer\": {\n",
    "        \"retail_analyzer_index\": {\n",
    "          \"tokenizer\":  \"standard\",\n",
    "          \"filter\": [\n",
    "            \"english_possessive_stemmer\",\n",
    "            \"lowercase\",\n",
    "            \"retail_syn_filter_index\",\n",
    "            \"english_stop\",\n",
    "            \"english_keywords\",\n",
    "            \"english_stemmer\"]},\n",
    "        \"retail_analyzer_search\": {\n",
    "          \"tokenizer\":  \"standard\",\n",
    "          \"filter\": [\n",
    "            \"english_possessive_stemmer\",\n",
    "            \"lowercase\",\n",
    "            \"retail_syn_filter_search\",\n",
    "            \"english_stop\",\n",
    "            \"english_keywords\",\n",
    "            \"english_stemmer\"]}}}},\n",
    "  \"mappings\": {\n",
    "    \"items\": {\n",
    "      \"properties\": {\n",
    "        \"desc\": {\n",
    "          \"type\": \"text\",\n",
    "          \"analyzer\": \"retail_analyzer_index\",\n",
    "          \"search_analyzer\": \"retail_analyzer_search\",\n",
    "}}}}})\n",
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/items/1', json={ \"desc\": \"bob's brand dress shoes are the bomb diggity\" }))\n",
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/items/2', json={ \"desc\": \"this little black dress is sure to impress\" }))\n",
    "print(requests.put(ELASTICSEARCH_URL + '/my_library/items/3', json={ \"desc\": \"tennis shoes... you know, for tennis\" }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for this little black dress is sure to impress\n",
      "0.2876821, weight(desc:dress in 0) [PerFieldSimilarity], result of:\n",
      "  0.2876821, score(doc=0,freq=1.0 = termFreq=1.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.0, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      1.0, termFreq=1.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      5.0, avgFieldLength\n",
      "      5.0, fieldLength\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "  \"explain\": \"true\",\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"desc\": \"dress\"\n",
    "}}}\n",
    "response = requests.get(ELASTICSEARCH_URL + '/my_library/items/_search', json=query)\n",
    "data = response.json()\n",
    "for i in range(len(data['hits']['hits'])):\n",
    "    print(\"Explain for %s\" % data['hits']['hits'][i]['_source']['desc'])\n",
    "    print(simpler_explain(data['hits']['hits'][i]['_explanation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for bob's brand dress shoes are the bomb diggity\n",
      "0.30873197, weight(desc:shoe in 0) [PerFieldSimilarity], result of:\n",
      "  0.30873197, score(doc=0,freq=1.0 = termFreq=1.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.0731707, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      1.0, termFreq=1.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      6.0, avgFieldLength\n",
      "      5.0, fieldLength\n",
      "\n",
      "Explain for tennis shoes... you know, for tennis\n",
      "0.2876821, weight(desc:shoe in 0) [PerFieldSimilarity], result of:\n",
      "  0.2876821, score(doc=0,freq=1.0 = termFreq=1.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.0, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      1.0, termFreq=1.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      5.0, avgFieldLength\n",
      "      5.0, fieldLength\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "  \"explain\": \"true\",\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"desc\": \"shoes\"\n",
    "}}}\n",
    "response = requests.get(ELASTICSEARCH_URL + '/my_library/items/_search', json=query)\n",
    "data = response.json()\n",
    "for i in range(len(data['hits']['hits'])):\n",
    "    print(\"Explain for %s\" % data['hits']['hits'][i]['_source']['desc'])\n",
    "    print(simpler_explain(data['hits']['hits'][i]['_explanation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for bob's brand dress shoes are the bomb diggity\n",
      "0.30873197, weight(desc:dress_sho in 0) [PerFieldSimilarity], result of:\n",
      "  0.30873197, score(doc=0,freq=1.0 = termFreq=1.0), product of:\n",
      "    0.2876821, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "      1.0, docFreq\n",
      "      1.0, docCount\n",
      "    1.0731707, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "      1.0, termFreq=1.0\n",
      "      1.2, parameter k1\n",
      "      0.75, parameter b\n",
      "      6.0, avgFieldLength\n",
      "      5.0, fieldLength\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "  \"explain\": \"true\",\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"desc\": \"dress shoes\"\n",
    "}}}\n",
    "response = requests.get(ELASTICSEARCH_URL + '/my_library/items/_search', json=query)\n",
    "data = response.json()\n",
    "for i in range(len(data['hits']['hits'])):\n",
    "    print(\"Explain for %s\" % data['hits']['hits'][i]['_source']['desc'])\n",
    "    print(simpler_explain(data['hits']['hits'][i]['_explanation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "Takeaways:\n",
    "\n",
    "1. ?\n",
    "\n",
    "Experiments:\n",
    "\n",
    "- **[1]**: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
