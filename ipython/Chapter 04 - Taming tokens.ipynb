{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boilerplate Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import time\n",
    "\n",
    "ELASTICSEARCH_URL = os.environ.get('ELASTICSEARCH_URL', 'http://localhost:9292')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2.2 Analysis for precision or recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex(settings):\n",
    "    response = requests.delete(ELASTICSEARCH_URL + '/my_library')\n",
    "    response = requests.put(ELASTICSEARCH_URL + '/my_library', json=settings)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, analyzer):\n",
    "    response = requests.get(\n",
    "        ELASTICSEARCH_URL + '/my_library/_analyze', \n",
    "        json={'text': text, 'analyzer': analyzer},\n",
    "    ).json()\n",
    "    \n",
    "    print(''.join(['[{}]'.format(token_term['token']) for token_term in response['tokens']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dr][strangelove][how][i][learned][stop][worrying][love][bomb]\n"
     ]
    }
   ],
   "source": [
    "reindex({'settings': {'analysis': {'analyzer': {'standard_clone': {'tokenizer': 'standard',\n",
    "                                                                   'filter': ['lowercase',\n",
    "                                                                              'stop']}}}}})\n",
    "\n",
    "tokenize(\"Dr. Strangelove: Or How I Learned to Stop Worrying and Love the Bomb\", 'standard_clone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dr][strangelov][how][i][learn][stop][worri][love][bomb]\n"
     ]
    }
   ],
   "source": [
    "reindex({'settings': {'analysis': {'filter': {'english_stop': {'type': 'stop',\n",
    "                                                               'stopwords':  '_english_'},\n",
    "                                              'english_keywords': {'type': 'keyword_marker',\n",
    "                                                                   'keywords':   []},\n",
    "                                              'english_stemmer': {'type': 'stemmer',\n",
    "                                                                  'language': 'english'},\n",
    "                                              'english_possessive_stemmer': {'type': 'stemmer',\n",
    "                                                                             'language': 'possessive_english'}},\n",
    "                                   'analyzer': {'english_clone': {'tokenizer': 'standard',\n",
    "                                                                  'filter': ['english_possessive_stemmer',\n",
    "                                                                             'lowercase',\n",
    "                                                                             'english_stop',\n",
    "                                                                             'english_keywords',\n",
    "                                                                             'english_stemmer']}}}}})\n",
    "\n",
    "tokenize(\"Dr. Strangelove: Or How I Learned to Stop Worrying and Love the Bomb\", 'english_clone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2.3 Taking recall to extremes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phonetic analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.bouncycastle.jcajce.provider.drbg.DRBG (file:/usr/share/elasticsearch/lib/tools/plugin-cli/bcprov-jdk15on-1.61.jar) to constructor sun.security.provider.Sun()\n",
      "WARNING: Please consider reporting this to the maintainers of org.bouncycastle.jcajce.provider.drbg.DRBG\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$ELASTICSEARCH_URL\"\n",
    "docker exec relsearch bash -c \"bin/elasticsearch-plugin install analysis-phonetic >/dev/null\"\n",
    "docker restart relsearch >/dev/null\n",
    "wget $1 --retry-connrefused --tries=10 -q --wait=10 --spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reindex({'settings': {'analysis': {'analyzer': {'phonetic': {'tokenizer': 'standard',\n",
    "                                                             'filter': ['lowercase',\n",
    "                                                                        'my_doublemetaphone']}},\n",
    "                                   'filter': {'my_doublemetaphone': {'type': 'phonetic',\n",
    "                                                                     'encoder': 'doublemetaphone',\n",
    "                                                                     'replace': True}}}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MSJ][MSK][FRM][TL][LM]\n",
      "[MSJ][MSK][FRM][TL][LM]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"message from Dalai Lama\", 'phonetic')\n",
    "tokenize(\"message from tall llama\", 'phonetic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3.1 Scoring strength of a feature in a single field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put(id, item):\n",
    "    requests.put(ELASTICSEARCH_URL + '/my_library/_doc/%d?refresh=wait_for' % id, json=item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "put(1, {'title': \"apple apple apple apple apple\"})\n",
    "put(2, {'title': \"apple apple apple banana banana\"})\n",
    "put(3, {'title': \"apple banana blueberry coconut\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpler_explain(explain_json, depth=0):\n",
    "    result = \" \" * (depth * 2) + \"%s, %s\\n\" % (explain_json['value'], explain_json['description'].replace('\\n', ''))\n",
    "    if 'details' in explain_json:\n",
    "        for detail in explain_json['details']:\n",
    "            result += simpler_explain(detail, depth=depth+1)\n",
    "    return result\n",
    "\n",
    "def search_explain(query):\n",
    "    query['explain'] = True\n",
    "    response = requests.get(ELASTICSEARCH_URL + '/my_library/_search', json=query)\n",
    "    data = response.json()\n",
    "    for i in range(len(data['hits']['hits'])):\n",
    "        print(\"Explain for `%s`\" % data['hits']['hits'][i]['_source']['title'])\n",
    "        print(simpler_explain(data['hits']['hits'][i]['_explanation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for `apple apple apple apple apple`\n",
      "0.2344793, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.2344793, score(freq=5.0), product of:\n",
      "    2.2, boost\n",
      "    0.13353139, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "      3, n, number of documents containing term\n",
      "      3, N, total number of documents with field\n",
      "    0.7981756, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "      5.0, freq, occurrences of term within document\n",
      "      1.2, k1, term saturation parameter\n",
      "      0.75, b, length normalization parameter\n",
      "      5.0, dl, length of field\n",
      "      4.6666665, avgdl, average length of field\n",
      "\n",
      "Explain for `apple apple apple banana banana`\n",
      "0.20667168, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.20667168, score(freq=3.0), product of:\n",
      "    2.2, boost\n",
      "    0.13353139, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "      3, n, number of documents containing term\n",
      "      3, N, total number of documents with field\n",
      "    0.70351756, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "      3.0, freq, occurrences of term within document\n",
      "      1.2, k1, term saturation parameter\n",
      "      0.75, b, length normalization parameter\n",
      "      5.0, dl, length of field\n",
      "      4.6666665, avgdl, average length of field\n",
      "\n",
      "Explain for `apple banana blueberry coconut`\n",
      "0.14181955, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.14181955, score(freq=1.0), product of:\n",
      "    2.2, boost\n",
      "    0.13353139, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "      3, n, number of documents containing term\n",
      "      3, N, total number of documents with field\n",
      "    0.4827586, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "      1.0, freq, occurrences of term within document\n",
      "      1.2, k1, term saturation parameter\n",
      "      0.75, b, length normalization parameter\n",
      "      4.0, dl, length of field\n",
      "      4.6666665, avgdl, average length of field\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {'explain': 'true',\n",
    "         'query': {'match': {'title': \"apple\"}}}\n",
    "\n",
    "search_explain(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "put(4, {'title': \"apples apple\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for `apple apple apple apple apple`\n",
      "0.18038376, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.18038376, score(freq=5.0), product of:\n",
      "    2.2, boost\n",
      "    0.105360515, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "      4, n, number of documents containing term\n",
      "      4, N, total number of documents with field\n",
      "    0.7782101, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "      5.0, freq, occurrences of term within document\n",
      "      1.2, k1, term saturation parameter\n",
      "      0.75, b, length normalization parameter\n",
      "      5.0, dl, length of field\n",
      "      4.0, avgdl, average length of field\n",
      "\n",
      "Explain for `apple apple apple banana banana`\n",
      "0.1571479, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.1571479, score(freq=3.0), product of:\n",
      "    2.2, boost\n",
      "    0.105360515, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "      4, n, number of documents containing term\n",
      "      4, N, total number of documents with field\n",
      "    0.6779661, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "      3.0, freq, occurrences of term within document\n",
      "      1.2, k1, term saturation parameter\n",
      "      0.75, b, length normalization parameter\n",
      "      5.0, dl, length of field\n",
      "      4.0, avgdl, average length of field\n",
      "\n",
      "Explain for `apples apple`\n",
      "0.13245323, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.13245323, score(freq=1.0), product of:\n",
      "    2.2, boost\n",
      "    0.105360515, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "      4, n, number of documents containing term\n",
      "      4, N, total number of documents with field\n",
      "    0.5714286, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "      1.0, freq, occurrences of term within document\n",
      "      1.2, k1, term saturation parameter\n",
      "      0.75, b, length normalization parameter\n",
      "      2.0, dl, length of field\n",
      "      4.0, avgdl, average length of field\n",
      "\n",
      "Explain for `apple banana blueberry coconut`\n",
      "0.105360515, weight(title:apple in 0) [PerFieldSimilarity], result of:\n",
      "  0.105360515, score(freq=1.0), product of:\n",
      "    2.2, boost\n",
      "    0.105360515, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "      4, n, number of documents containing term\n",
      "      4, N, total number of documents with field\n",
      "    0.45454544, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "      1.0, freq, occurrences of term within document\n",
      "      1.2, k1, term saturation parameter\n",
      "      0.75, b, length normalization parameter\n",
      "      4.0, dl, length of field\n",
      "      4.0, avgdl, average length of field\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {'explain': 'true',\n",
    "         'query': {'match': {'title': \"apple\"}}}\n",
    "\n",
    "search_explain(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reindex({'mappings': {'properties': {'title': {'type': 'text', 'analyzer': 'english'},\n",
    "                                     'overview': {'type': 'text', 'analyzer': 'english'}}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "put(1, {'title': \"apple apple apple apple apple\"})\n",
    "put(2, {'title': \"apple apple apple banana banana\"})\n",
    "put(3, {'title': \"apple banana blueberry coconut\"})\n",
    "put(4, {'title': \"apples apple\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for `apple apple apple apple apple`\n",
      "0.18038376, weight(title:appl in 0) [PerFieldSimilarity], result of:\n",
      "  0.18038376, score(freq=5.0), product of:\n",
      "    2.2, boost\n",
      "    0.105360515, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "      4, n, number of documents containing term\n",
      "      4, N, total number of documents with field\n",
      "    0.7782101, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "      5.0, freq, occurrences of term within document\n",
      "      1.2, k1, term saturation parameter\n",
      "      0.75, b, length normalization parameter\n",
      "      5.0, dl, length of field\n",
      "      4.0, avgdl, average length of field\n",
      "\n",
      "Explain for `apples apple`\n",
      "0.16857684, weight(title:appl in 0) [PerFieldSimilarity], result of:\n",
      "  0.16857684, score(freq=2.0), product of:\n",
      "    2.2, boost\n",
      "    0.105360515, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "      4, n, number of documents containing term\n",
      "      4, N, total number of documents with field\n",
      "    0.72727275, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "      2.0, freq, occurrences of term within document\n",
      "      1.2, k1, term saturation parameter\n",
      "      0.75, b, length normalization parameter\n",
      "      2.0, dl, length of field\n",
      "      4.0, avgdl, average length of field\n",
      "\n",
      "Explain for `apple apple apple banana banana`\n",
      "0.1571479, weight(title:appl in 0) [PerFieldSimilarity], result of:\n",
      "  0.1571479, score(freq=3.0), product of:\n",
      "    2.2, boost\n",
      "    0.105360515, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "      4, n, number of documents containing term\n",
      "      4, N, total number of documents with field\n",
      "    0.6779661, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "      3.0, freq, occurrences of term within document\n",
      "      1.2, k1, term saturation parameter\n",
      "      0.75, b, length normalization parameter\n",
      "      5.0, dl, length of field\n",
      "      4.0, avgdl, average length of field\n",
      "\n",
      "Explain for `apple banana blueberry coconut`\n",
      "0.105360515, weight(title:appl in 0) [PerFieldSimilarity], result of:\n",
      "  0.105360515, score(freq=1.0), product of:\n",
      "    2.2, boost\n",
      "    0.105360515, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "      4, n, number of documents containing term\n",
      "      4, N, total number of documents with field\n",
      "    0.45454544, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "      1.0, freq, occurrences of term within document\n",
      "      1.2, k1, term saturation parameter\n",
      "      0.75, b, length normalization parameter\n",
      "      4.0, dl, length of field\n",
      "      4.0, avgdl, average length of field\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {'explain': 'true',\n",
    "         'query': {'match': {'title': \"apple\"}}}\n",
    "\n",
    "search_explain(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4.1 Dealing with delimiters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i.b.m][versus][ibm][versus][ibm]\n",
      "[ibm][versus][ibm][versus][ibm]\n"
     ]
    }
   ],
   "source": [
    "reindex({'settings': {'analysis': {'filter': {'acronyms': {'type': 'word_delimiter',\n",
    "                                                           'catenate_all': True,\n",
    "                                                           'generate_word_parts': False,\n",
    "                                                           'generate_number_parts': False}},\n",
    "                                   'analyzer': {'standard_with_acronyms': {'tokenizer': 'standard',\n",
    "                                                                           'filter': ['lowercase',\n",
    "                                                                                      'acronyms']}}}}})\n",
    "\n",
    "tokenize(\"I.B.M. versus IBM versus ibm\", 'standard')\n",
    "tokenize(\"I.B.M. versus IBM versus ibm\", 'standard_with_acronyms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phone numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1][800][867][5309]\n",
      "[18008675309][8008675309][8675309]\n"
     ]
    }
   ],
   "source": [
    "reindex({'settings': {'analysis': {'filter': {'phone_num_filter': {'type': 'word_delimiter',\n",
    "                                                                   'catenate_all': True,\n",
    "                                                                   'generate_number_parts': False},\n",
    "                                              'phone_num_parts': {'type': 'pattern_capture',\n",
    "                                                                  'patterns':[\"(\\\\d{7}$)\",\"(\\\\d{10}$)\"],\n",
    "                                                                  'preserve_original': True}},\n",
    "                                   'analyzer': {'phone_num': {'tokenizer': 'keyword',\n",
    "                                                              'filter': ['phone_num_filter',\n",
    "                                                                         'phone_num_parts']}}}}})\n",
    "\n",
    "tokenize(\"1(800)867-5309\", 'standard')\n",
    "tokenize(\"1(800)867-5309\", 'phone_num')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4.2. Capturing meaning with synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reindex({'settings': {'analysis': {'filter': {'english_stop': {'type': 'stop',\n",
    "                                                               'stopwords':  '_english_'},\n",
    "                                              'english_keywords': {'type': 'keyword_marker',\n",
    "                                                                   'keywords':   []},\n",
    "                                              'english_stemmer': {'type': 'stemmer',\n",
    "                                                                  'language': 'english'},\n",
    "                                              'english_possessive_stemmer': {'type': 'stemmer',\n",
    "                                                                             'language': 'possessive_english'},\n",
    "                                              'retail_syn_filter': {'type': 'synonym',\n",
    "                                                                    'synonyms': ['dress shoe, dress shoes => dress_shoe, shoe']}},\n",
    "                                   'analyzer': {'retail_analyzer': {'tokenizer':  'standard',\n",
    "                                                                    'filter': ['english_possessive_stemmer',\n",
    "                                                                               'lowercase',\n",
    "                                                                               'retail_syn_filter',\n",
    "                                                                               'english_keywords',\n",
    "                                                                               'english_stemmer']}}}},\n",
    "         'mappings': {'properties': {'title': {'type': 'text',\n",
    "                                               'analyzer': 'retail_analyzer'}}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "put(1, {'title': \"bob's brand dress shoes are the bomb diggity\"})\n",
    "put(2, {'title': \"this little black dress is sure to impress\"})\n",
    "put(3, {'title': \"tennis shoes... you know, for tennis\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for `this little black dress is sure to impress`\n",
      "0.94566005, weight(title:dress in 0) [PerFieldSimilarity], result of:\n",
      "  0.94566005, score(freq=1.0), product of:\n",
      "    2.2, boost\n",
      "    0.98082924, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "      1, n, number of documents containing term\n",
      "      3, N, total number of documents with field\n",
      "    0.43824703, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "      1.0, freq, occurrences of term within document\n",
      "      1.2, k1, term saturation parameter\n",
      "      0.75, b, length normalization parameter\n",
      "      8.0, dl, length of field\n",
      "      7.3333335, avgdl, average length of field\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {'explain': 'true',\n",
    "         'query': {'match': {'title': \"dress\"}}}\n",
    "\n",
    "search_explain(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for `tennis shoes... you know, for tennis`\n",
      "0.5077718, weight(title:shoe in 0) [PerFieldSimilarity], result of:\n",
      "  0.5077718, score(freq=1.0), product of:\n",
      "    2.2, boost\n",
      "    0.47000363, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "      2, n, number of documents containing term\n",
      "      3, N, total number of documents with field\n",
      "    0.4910714, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "      1.0, freq, occurrences of term within document\n",
      "      1.2, k1, term saturation parameter\n",
      "      0.75, b, length normalization parameter\n",
      "      6.0, dl, length of field\n",
      "      7.3333335, avgdl, average length of field\n",
      "\n",
      "Explain for `bob's brand dress shoes are the bomb diggity`\n",
      "0.478909, weight(title:shoe in 0) [PerFieldSimilarity], result of:\n",
      "  0.478909, score(freq=1.0), product of:\n",
      "    2.2, boost\n",
      "    0.47000363, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "      2, n, number of documents containing term\n",
      "      3, N, total number of documents with field\n",
      "    0.4631579, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "      1.0, freq, occurrences of term within document\n",
      "      1.2, k1, term saturation parameter\n",
      "      0.75, b, length normalization parameter\n",
      "      7.0, dl, length of field\n",
      "      7.3333335, avgdl, average length of field\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {'explain': 'true',\n",
    "         'query': {'match': {'title': \"shoes\"}}}\n",
    "\n",
    "search_explain(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for `bob's brand dress shoes are the bomb diggity`\n",
      "0.6546238, weight(Synonym(title:dress_sho title:shoe) in 0) [PerFieldSimilarity], result of:\n",
      "  0.6546238, score(freq=2.0), product of:\n",
      "    2.2, boost\n",
      "    0.47000363, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "      2, n, number of documents containing term\n",
      "      3, N, total number of documents with field\n",
      "    0.63309354, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "      2.0, termFreq=2.0\n",
      "      1.2, k1, term saturation parameter\n",
      "      0.75, b, length normalization parameter\n",
      "      7.0, dl, length of field\n",
      "      7.3333335, avgdl, average length of field\n",
      "\n",
      "Explain for `tennis shoes... you know, for tennis`\n",
      "0.5077718, weight(Synonym(title:dress_sho title:shoe) in 0) [PerFieldSimilarity], result of:\n",
      "  0.5077718, score(freq=1.0), product of:\n",
      "    2.2, boost\n",
      "    0.47000363, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "      2, n, number of documents containing term\n",
      "      3, N, total number of documents with field\n",
      "    0.4910714, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "      1.0, termFreq=1.0\n",
      "      1.2, k1, term saturation parameter\n",
      "      0.75, b, length normalization parameter\n",
      "      6.0, dl, length of field\n",
      "      7.3333335, avgdl, average length of field\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {'explain': 'true',\n",
    "         'query': {'match': {'title': \"dress shoes\"}}}\n",
    "\n",
    "search_explain(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reindex({'settings': {'analysis': {'filter': {'english_stop': {'type': 'stop',\n",
    "                                                                   'stopwords':  '_english_'},\n",
    "                                                  'english_keywords': {'type': 'keyword_marker',\n",
    "                                                                       'keywords':   []},\n",
    "                                                  'english_stemmer': {'type': 'stemmer',\n",
    "                                                                      'language':   'english'},\n",
    "                                                  'english_possessive_stemmer': {'type': 'stemmer',\n",
    "                                                                                 'language': 'possessive_english'},\n",
    "                                                  'retail_syn_filter_index': {'type': 'synonym',\n",
    "                                                                              'synonyms': ['dress shoe, dress shoes => dress_shoe, shoe']},\n",
    "                                                  'retail_syn_filter_search': {'type': 'synonym',\n",
    "                                                                               'synonyms': ['dress shoe, dress shoes => dress_shoe']}},\n",
    "                                       'analyzer': {'retail_analyzer_index': {'tokenizer':  'standard',\n",
    "                                                                              'filter': ['english_possessive_stemmer',\n",
    "                                                                                         'lowercase',\n",
    "                                                                                         'retail_syn_filter_index',\n",
    "                                                                                         'english_stop',\n",
    "                                                                                         'english_keywords',\n",
    "                                                                                         'english_stemmer']},\n",
    "                                                    'retail_analyzer_search': {'tokenizer':  'standard',\n",
    "                                                                               'filter': ['english_possessive_stemmer',\n",
    "                                                                                          'lowercase',\n",
    "                                                                                          'retail_syn_filter_search',\n",
    "                                                                                          'english_stop',\n",
    "                                                                                          'english_keywords',\n",
    "                                                                                          'english_stemmer']}}}},\n",
    "             'mappings': {'properties': {'title': {'type': 'text',\n",
    "                                                   'analyzer': 'retail_analyzer_index',\n",
    "                                                   'search_analyzer': 'retail_analyzer_search'}}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "put(1, {'title': \"bob's brand dress shoes are the bomb diggity\"})\n",
    "put(2, {'title': \"this little black dress is sure to impress\"})\n",
    "put(3, {'title': \"tennis shoes... you know, for tennis\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for `this little black dress is sure to impress`\n",
      "1.0065652, weight(title:dress in 0) [PerFieldSimilarity], result of:\n",
      "  1.0065652, score(freq=1.0), product of:\n",
      "    2.2, boost\n",
      "    0.98082924, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "      1, n, number of documents containing term\n",
      "      3, N, total number of documents with field\n",
      "    0.4664723, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "      1.0, freq, occurrences of term within document\n",
      "      1.2, k1, term saturation parameter\n",
      "      0.75, b, length normalization parameter\n",
      "      5.0, dl, length of field\n",
      "      5.3333335, avgdl, average length of field\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {'explain': 'true',\n",
    "         'query': {'match': {'title': \"dress\"}}}\n",
    "\n",
    "search_explain(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for `bob's brand dress shoes are the bomb diggity`\n",
      "0.4823361, weight(title:shoe in 0) [PerFieldSimilarity], result of:\n",
      "  0.4823361, score(freq=1.0), product of:\n",
      "    2.2, boost\n",
      "    0.47000363, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "      2, n, number of documents containing term\n",
      "      3, N, total number of documents with field\n",
      "    0.4664723, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "      1.0, freq, occurrences of term within document\n",
      "      1.2, k1, term saturation parameter\n",
      "      0.75, b, length normalization parameter\n",
      "      5.0, dl, length of field\n",
      "      5.3333335, avgdl, average length of field\n",
      "\n",
      "Explain for `tennis shoes... you know, for tennis`\n",
      "0.4823361, weight(title:shoe in 0) [PerFieldSimilarity], result of:\n",
      "  0.4823361, score(freq=1.0), product of:\n",
      "    2.2, boost\n",
      "    0.47000363, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "      2, n, number of documents containing term\n",
      "      3, N, total number of documents with field\n",
      "    0.4664723, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "      1.0, freq, occurrences of term within document\n",
      "      1.2, k1, term saturation parameter\n",
      "      0.75, b, length normalization parameter\n",
      "      5.0, dl, length of field\n",
      "      5.3333335, avgdl, average length of field\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {'explain': 'true',\n",
    "         'query': {'match': {'title': \"shoes\"}}}\n",
    "\n",
    "search_explain(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for `bob's brand dress shoes are the bomb diggity`\n",
      "1.0065652, weight(title:dress_sho in 0) [PerFieldSimilarity], result of:\n",
      "  1.0065652, score(freq=1.0), product of:\n",
      "    2.2, boost\n",
      "    0.98082924, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "      1, n, number of documents containing term\n",
      "      3, N, total number of documents with field\n",
      "    0.4664723, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "      1.0, freq, occurrences of term within document\n",
      "      1.2, k1, term saturation parameter\n",
      "      0.75, b, length normalization parameter\n",
      "      5.0, dl, length of field\n",
      "      5.3333335, avgdl, average length of field\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {'explain': 'true',\n",
    "         'query': {'match': {'title': \"dress shoes\"}}}\n",
    "\n",
    "search_explain(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4.5. Modeling specificity with paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reindex({'settings': {'analysis': {'analyzer': {'path_hierarchy': {'tokenizer': 'path_hierarchy'}}}},\n",
    "         'mappings': {'properties': {'inventory_dir': {'type': 'text',\n",
    "                                                       'analyzer': 'path_hierarchy'}}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "put(1, {'inventory_dir': '/fruit/apples/fuji', 'title': \"crisp, sweet-flavored, long shelf-life\"})\n",
    "put(2, {'inventory_dir': '/fruit/apples/gala', 'title ': \"sweet, pleasant apple\"})\n",
    "put(3, {'inventory_dir': '/fruit', 'title ': \"edible, seed-bearing portion of plants\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for `crisp, sweet-flavored, long shelf-life`\n",
      "1.2800652, weight(inventory_dir:/fruit/apples/fuji in 0) [PerFieldSimilarity], result of:\n",
      "  1.2800652, score(freq=1.0), product of:\n",
      "    2.2, boost\n",
      "    0.98082924, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "      1, n, number of documents containing term\n",
      "      3, N, total number of documents with field\n",
      "    0.5932203, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "      1.0, freq, occurrences of term within document\n",
      "      1.2, k1, term saturation parameter\n",
      "      0.75, b, length normalization parameter\n",
      "      1.0, dl, length of field\n",
      "      2.3333333, avgdl, average length of field\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {'query': {'bool': {'should': [{'term': {'inventory_dir': '/fruit/apples/fuji'}}]}}}\n",
    "\n",
    "search_explain(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a specialized Path Hierarchy Tokenizer that can be used to control the specificity of the query or index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4.9. Tokenizing melodies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reindex({'settings': {'analysis': {'filter': {'parsons-ngram': {'type': 'nGram',\n",
    "                                                                'min_gram': 5,\n",
    "                                                                'max_gram': 5}},\n",
    "                                   'analyzer': {'parsons': {'tokenizer': 'keyword',\n",
    "                                                            'filter': ['parsons-ngram']}}}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*RRDU][RRDUR][RDURD][DURDU][URDUR][RDURD][DURDR][URDRD]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"*RRDURDURDRD\", 'parsons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reindex({'settings': {'analysis': {'filter': {'parsons-ngram': {'type': 'nGram',\n",
    "                                                                'min_gram': 4,\n",
    "                                                                'max_gram': 5}},\n",
    "                                   'analyzer': {'parsons': {'tokenizer': 'keyword',\n",
    "                                                            'filter': ['parsons-ngram']}}}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*RRD][*RRDU][RRDU][RRDUR][RDUR][RDURD][DURD][DURDU][URDU][URDUR][RDUR][RDURD][DURD][DURDR][URDR][URDRD][RDRD]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"*RRDURDURDRD\", 'parsons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "Takeaways:\n",
    "\n",
    "1. Generalizing a concept either by synonym lists or tokenization techniques is called *semantic expansion* and is the basis of assymetric analysis.\n",
    "2. Asymmetric analysis allows general concepts to be extracted at index or query time. This can be used to make answer queries with generalized or specialized concepts.\n",
    "3. This is the default behavior on several built-in filters and analyzers, like integers or geopoints. It also allows efficient querying of ranges and different levels of precision.\n",
    "\n",
    "Experiments:\n",
    "\n",
    "- **[1,2]**: Mapping expressions to a concise term that represents the concept like `dress shoe -> dress_shoe, shoe` will guarantee us the ability to treat \"dress shoes\" as shoe, as a specific type of shoe and not as dress."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
